\section{Approaches}\label{sec:Approaches}
We want to find the language for every word inside a tweet. For this we use a two step approach. The first step is to train and use a machine learning algorithm. And the next step is to check its results and improve it using our knowledge about code-switching and statistical approximations. \\
Goal of the machine learning algorithm is it to look at a single word and decide which language it is. Thus we use uni- and bigrams to train the algorithm. The unigrams are every character used in the tweets, and the bigrams is a combination of every character with every character. After we obtained the uni- and bigrams we looked up every distinct word in the provided tweets. The next step was to write down a table which sowed for each word which uni- and bigrams it contains. Additional we provided the table with the language from which the word is. This way we have a table with one column containing each word. Then one column for each possible bigram and if each word contains this bigram. Lastly a column with the label from which language the word is from. We havent used trigrams since the paper \cite{multipleLanguages} already showed that trigrams wont improve the machinelearning algorithm. The next improvement is reached when using nGrams in the length of the words. But since the trigram table would have had required around 20Gbyte we did not perform this step either. The nGrams in length of words would have been resulting in a hardware problem.\\
This table is then useful in combination with the Python libraries Pandas and Sklearn.
The first machine-learning algorithm we tested was a Linear Regression. Using unigrams we had 64\% accuracy and with bigrams 84\%.  \\